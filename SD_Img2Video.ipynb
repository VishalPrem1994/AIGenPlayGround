{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmITfIsA61+1ErvOzkhkc4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishalPrem1994/AIGenPlayGround/blob/main/SD_Img2Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai numpy opencv-python accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers diffusers omegaconf requests"
      ],
      "metadata": {
        "id": "b_4jEZt8b1MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RQ6Q7J1b5Lx",
        "outputId": "6ba3364a-5df7-4698-e370-e7d6043270e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "import os\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/stable_diffusion_weights/RevAnim\"\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "device = \"cuda\"\n",
        "model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lhzfMgcc8RK",
        "outputId": "7428a225-9240-459d-901b-4a9eafcd3dee"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_folder = \"Bike1\" #@param {type:\"string\"}\n",
        "prompt = \"anime, highly detailed, intricate, natural lighting\" #@param {type:\"string\"}\n",
        "negative_prompt = \"(worst quality:1.4), (low quality:1.4), child, deformed, deformed face, bad hands, bad fingers, bad hands, (3d, render, cgi, doll, painting:1.4), long body, blurry, duplicate, cloned, duplicate body parts, disfigured, extra limbs, fused fingers, extra fingers, twisted, malformed hands, mutated hands and fingers, conjoined, missing limbs, bad anatomy, bad proportions, logo, signature, text, words, lowres, boring, mutated, artifacts, gross, ugly, stretch, smooth skin texture\"\n",
        "num_samples = 1\n",
        "guidance_scale = 8 #@param {type:\"number\"}\n",
        "strength = 0.6 #@param {type:\"number\"}\n",
        "num_inference_steps = 50"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uMn1AQeVydrU"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "main_path = \"/content/drive/MyDrive/AI/VideoInput/\"\n",
        "fullpath = main_path+selected_folder\n",
        "print(fullpath)\n",
        "output_folder = fullpath+\"/Output\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "  for i in os.listdir(fullpath):\n",
        "    print(i)\n",
        "    if i.endswith(\".jpg\"):\n",
        "      num = i.split(\"-\")[1]\n",
        "      print(num)\n",
        "      init_image = Image.open(fullpath+\"/\"+i).convert(\"RGB\")\n",
        "      images = pipe(\n",
        "          prompt=prompt,\n",
        "          image=init_image,\n",
        "          strength=strength,\n",
        "          guidance_scale=guidance_scale,\n",
        "          num_images_per_prompt = num_samples,\n",
        "          num_inference_steps = num_inference_steps,\n",
        "          generator=g_cuda\n",
        "          ).images\n",
        "      output_path = fullpath+\"/\"+\"Output/\"+\"image2-\"+str(num)\n",
        "      print(output_path)\n",
        "      images[0].save(output_path)"
      ],
      "metadata": {
        "id": "F0Mbe3TIwwPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vi9MOlSN3jB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "image_folder = output_folder\n",
        "print(output_folder)\n",
        "video_name = output_folder+'/video.avi'\n",
        "\n",
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
        "images.sort()\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "video = cv2.VideoWriter(video_name, 0, 5, (width,height))\n",
        "\n",
        "for image in images:\n",
        "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcKJv62qxIXn",
        "outputId": "6a883768-ee64-4852-a558-053b15bd0c20"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI/VideoInput/Bike2/Output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wuExljEv68fk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}