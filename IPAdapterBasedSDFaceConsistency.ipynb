{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOc85UWHkPqWUW7r605uz1y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishalPrem1994/AIGenPlayGround/blob/main/IPAdapterBasedSDFaceConsistency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WR87xEiSBDR",
        "outputId": "5ce6d66f-7f99-46b6-8d0d-76518fd6a8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install openai numpy opencv-python accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers diffusers omegaconf requests\n",
        "%pip install opencv-python insightface onnxruntime\n",
        "%pip install git+https://github.com/tencent-ailab/IP-Adapter.git einops"
      ],
      "metadata": {
        "id": "LW_mRCwFVL3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwbemQenM179"
      },
      "outputs": [],
      "source": [
        "import insightface\n",
        "import cv2\n",
        "from insightface.app import FaceAnalysis\n",
        "import torch\n",
        "\n",
        "app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "\n",
        "images = [\"/content/drive/MyDrive/stable_diffusion_weights/samples/1.jpg\", \"/content/drive/MyDrive/stable_diffusion_weights/samples/2.jpg\", \"/content/drive/MyDrive/stable_diffusion_weights/samples/3.jpg\", \"/content/drive/MyDrive/stable_diffusion_weights/samples/4.jpg\", \"/content/drive/MyDrive/stable_diffusion_weights/samples/5.jpg\"]\n",
        "\n",
        "faceid_embeds = []\n",
        "for image in images:\n",
        "    image = cv2.imread(image)\n",
        "    faces = app.get(image)\n",
        "    faceid_embeds.append(torch.from_numpy(faces[0].normed_embedding).unsqueeze(0).unsqueeze(0))\n",
        "faceid_embeds = torch.cat(faceid_embeds, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler, AutoencoderKL\n",
        "from PIL import Image\n",
        "\n",
        "from ip_adapter.ip_adapter_faceid_separate import IPAdapterFaceID\n",
        "\n",
        "base_model_path = \"SG161222/Realistic_Vision_V4.0_noVAE\"\n",
        "vae_model_path = \"stabilityai/sd-vae-ft-mse\"\n",
        "ip_ckpt = \"/content/drive/MyDrive/stable_diffusion_weights/ip-adapter-faceid-portrait-v11_sd15.bin\"\n",
        "device = \"cuda\"\n",
        "\n",
        "noise_scheduler = DDIMScheduler(\n",
        "    num_train_timesteps=1000,\n",
        "    beta_start=0.00085,\n",
        "    beta_end=0.012,\n",
        "    beta_schedule=\"scaled_linear\",\n",
        "    clip_sample=False,\n",
        "    set_alpha_to_one=False,\n",
        "    steps_offset=1,\n",
        ")\n",
        "vae = AutoencoderKL.from_pretrained(vae_model_path).to(dtype=torch.float16)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"/content/drive/MyDrive/stable_diffusion_weights/RevAnim\",\n",
        "    torch_dtype=torch.float16,\n",
        "    scheduler=noise_scheduler,\n",
        "    vae=vae,\n",
        "    feature_extractor=None,\n",
        "    safety_checker=None\n",
        ")\n",
        "\n",
        "ip_model = IPAdapterFaceID(pipe, ip_ckpt, device, num_tokens=16, n_cond=5)"
      ],
      "metadata": {
        "id": "kj76W_D6PevW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35,
          "referenced_widgets": [
            "a8d93c42b82645159c2e70efd34187ad"
          ]
        },
        "outputId": "7d4a8f4f-fdb9-4e60-a1f1-35ec89c53904"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8d93c42b82645159c2e70efd34187ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# generate image\n",
        "prompt = \"close up portrait  of beautiful woman, strong jawline, (in fashion show, catwalk), saree, hijabi, (transparent silk), beautiful design outfits, smiling, intricate, detailed eyes, taken by nina masic\" #@param {type:\"string\"}\n",
        "negative_prompt = \"(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\" #@param {type:\"string\"}\n",
        "seed  = 34234234 #@param {type:\"number\"}\n",
        "width=512 #@param {type:\"number\"}\n",
        "height=512 #@param {type:\"number\"}\n",
        "images = ip_model.generate(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    faceid_embeds=faceid_embeds,\n",
        "    num_samples=2,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    num_inference_steps=25,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "\n",
        "for img in images:\n",
        "    display(img)"
      ],
      "metadata": {
        "id": "uL2NhwzPdALF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}